This project implements the OpenAI cookbook found [here](https://cookbook.openai.com/examples/object_oriented_agentic_approach/secure_code_interpreter_tool_for_llm_agents) using Ollama for local LLM model support.

It uses docker to run the LLM generated code in a safe environment.
